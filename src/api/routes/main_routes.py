"""
è¦–é »åˆ†æç›¸é—œè·¯ç”±å™¨æ¨¡çµ„
æœ¬æ¨¡çµ„è² è²¬ API ç«¯é»ã€ä»»å‹™åˆ†æ´¾ã€å¿«å–æŸ¥è©¢èˆ‡ç‹€æ…‹ç®¡ç†ï¼Œ
ä¸¦å°‡åˆ†æä»»å‹™åˆ†æ´¾çµ¦ crewai åŸ·è¡Œï¼Œæ”¯æ´å³æ™‚é€²åº¦æŸ¥è©¢ã€‚
"""

from fastapi import APIRouter, HTTPException, Path, BackgroundTasks
from fastapi.openapi.utils import get_openapi
from src.api.core.logger_config import get_logger
import uuid
from datetime import datetime, timezone
import re
from src.api.core.models import (
    AnalyzeRequest,
    JobResponse,
    JobStatusResponse,
    JobStatus,
    Phase,
    MapVisualization,
    SubtitleStatus,
)

# CacheManager å’Œ Trailtag å°‡åœ¨éœ€è¦æ™‚å‹•æ…‹åŒ¯å…¥ä»¥é¿å…å¾ªç’°ä¾è³´
from src.trailtag.tools.data_extraction.youtube_metadata import YoutubeMetadataTool


logger = get_logger(__name__)
router = APIRouter(prefix="/api")


def custom_openapi():
    if router.openapi_schema:
        return router.openapi_schema
    openapi_schema = get_openapi(
        title="TrailTag API",
        version="1.0.0",
        description="TrailTag å¾Œç«¯ APIï¼Œæä¾› YouTube å½±ç‰‡åˆ†æã€ä»»å‹™é€²åº¦æŸ¥è©¢èˆ‡åœ°é»è¦–è¦ºåŒ–è³‡æ–™ã€‚æ”¯æ´å¿«å–ã€éåŒæ­¥ä»»å‹™ã€SSE é€²åº¦æ¨æ’­ã€‚",
        routes=router.routes,
    )
    router.openapi_schema = openapi_schema
    return router.openapi_schema


router.openapi = custom_openapi


def get_cache():
    """ç²å–å¿«å–ç®¡ç†å™¨å¯¦ä¾‹ï¼ˆå»¶é²åŒ¯å…¥ï¼‰"""
    from src.api.cache.cache_manager import CacheManager

    return CacheManager()


def get_trailtag():
    """ç²å– Trailtag å¯¦ä¾‹ï¼ˆå»¶é²åŒ¯å…¥ï¼‰"""
    from src.trailtag.core.crew import Trailtag

    return Trailtag


def extract_video_id(url: str) -> str:
    """
    å¾ YouTube URL ä¸­æå– video_idã€‚
    æ”¯æ´å¤šç¨®å¸¸è¦‹ç¶²å€æ ¼å¼ï¼Œè‹¥ç„¡æ³•è§£æå‰‡æ‹‹å‡ºä¾‹å¤–ã€‚
    """
    patterns = [
        r"(?:v=|\/)([0-9A-Za-z_-]{11}).*",  # youtu.be/XXX or youtube.com/watch?v=XXX
        r"(?:embed\/|v\/|youtu\.be\/)([0-9A-Za-z_-]{11})",  # youtube.com/embed/XXX
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    raise ValueError(f"ç„¡æ³•å¾ URL æå–æœ‰æ•ˆçš„ YouTube video_id: {url}")


def check_subtitle_availability(video_id: str) -> SubtitleStatus:
    """
    å¿«é€Ÿæª¢æ¸¬å½±ç‰‡å­—å¹•å¯ç”¨æ€§ï¼Œç”¨æ–¼åœ¨åˆ†æé–‹å§‹å‰æä¾›ç”¨æˆ¶æç¤ºã€‚
    å„ªå…ˆæª¢æŸ¥ç·©å­˜ï¼Œé¿å…é‡è¤‡ä¸‹è¼‰å­—å¹•å°è‡´ Too Many Requests éŒ¯èª¤ã€‚

    Args:
        video_id (str): YouTube å½±ç‰‡ ID

    Returns:
        SubtitleStatus: å­—å¹•ç‹€æ…‹è³‡è¨Š
    """
    try:
        # å»¶é²åŒ¯å…¥é¿å…å¾ªç’°ä¾è³´
        from src.api.cache.cache_provider import get_cache

        cache = get_cache()

        # å…ˆæª¢æŸ¥æ˜¯å¦æœ‰å¿«å–çš„åˆ†æçµæœ
        cached_result = cache.get(f"analysis:{video_id}")
        if cached_result:
            logger.info(f"å¾å¿«å–ç²å–å½±ç‰‡ {video_id} çš„å­—å¹•ç‹€æ…‹")
            # å¦‚æœæœ‰åˆ†æçµæœï¼Œèªªæ˜å­—å¹•æ˜¯å¯ç”¨çš„ï¼ˆå¦å‰‡åˆ†æä¸æœƒæˆåŠŸï¼‰
            return SubtitleStatus(
                available=True,
                manual_subtitles=[],  # å¿«å–çµæœæ²’æœ‰è©³ç´°å­—å¹•é¡å‹è³‡è¨Š
                auto_captions=[],
                selected_lang="cached",  # æ¨™è¨˜ä¾†æºç‚ºå¿«å–
                confidence_score=0.9,  # å·²åˆ†æéçš„å½±ç‰‡ä¿¡å¿ƒåº¦è¼ƒé«˜
            )

        # å¦‚æœæ²’æœ‰å¿«å–ï¼Œæ‰é€²è¡Œå¯¦éš›æª¢æ¸¬
        logger.info(f"å¿«å–æœªå‘½ä¸­ï¼Œæª¢æ¸¬å½±ç‰‡ {video_id} å­—å¹•å¯ç”¨æ€§")
        metadata_tool = YoutubeMetadataTool()
        metadata = metadata_tool._run(video_id)

        if metadata and metadata.subtitle_availability:
            availability = metadata.subtitle_availability
            return SubtitleStatus(
                available=availability.available,
                manual_subtitles=availability.manual_subtitles,
                auto_captions=availability.auto_captions,
                selected_lang=availability.selected_lang,
                confidence_score=availability.confidence_score,
            )
        else:
            logger.warning(f"ç„¡æ³•æª¢æ¸¬å½±ç‰‡ {video_id} çš„å­—å¹•å¯ç”¨æ€§")
            return SubtitleStatus(
                available=False,
                manual_subtitles=[],
                auto_captions=[],
                selected_lang=None,
                confidence_score=0.0,
            )

    except Exception as e:
        logger.error(f"å­—å¹•å¯ç”¨æ€§æª¢æ¸¬å¤±æ•— {video_id}: {str(e)}")
        return SubtitleStatus(
            available=False,
            manual_subtitles=[],
            auto_captions=[],
            selected_lang=None,
            confidence_score=0.0,
        )


# --- èƒŒæ™¯ä»»å‹™ï¼šåŸ·è¡Œ crewai åˆ†æä¸¦å³æ™‚æ›´æ–° job ç‹€æ…‹ ---
def run_trailtag_job(job_id, video_id):
    """
    åŸ·è¡Œ crewai åˆ†ææµç¨‹ï¼Œä¸¦æ ¹æ“šéšæ®µå³æ™‚æ›´æ–° job ç‹€æ…‹èˆ‡é€²åº¦ã€‚
    1. ä¾ç…§åˆ†æéšæ®µï¼ˆmetadataâ†’geocodeï¼‰å³æ™‚å¯«å…¥ job ç‹€æ…‹ï¼Œä¾› SSE æŸ¥è©¢ã€‚
    2. è‹¥åˆ†ææˆåŠŸï¼Œå°‡çµæœå¯«å…¥ analysis å¿«å–ã€‚
    3. è‹¥å¤±æ•—å‰‡è¨˜éŒ„éŒ¯èª¤ä¸¦æ›´æ–° job ç‹€æ…‹ã€‚
    """
    try:
        # å»¶é²åŒ¯å…¥é¿å…å¾ªç’°ä¾è³´
        cache = get_cache()

        def update_job(
            phase, progress, status=JobStatus.RUNNING, extra=None, ttl: int = None
        ):
            """
            å¯«å…¥/æ›´æ–° job ç‹€æ…‹åˆ°å¿«å–ï¼Œä¾›é€²åº¦æŸ¥è©¢èˆ‡ SSE æ¨æ’­ã€‚
            æ”¯æ´å¯é¸çš„ ttlï¼ˆç§’ï¼‰åƒæ•¸ä»¥ä¾¿è¨­å®šçŸ­æš«ç”Ÿå‘½é€±æœŸçš„å®Œæˆç‹€æ…‹ã€‚
            """
            logger.info(
                f"ğŸ”„ æ›´æ–°ä»»å‹™ç‹€æ…‹ - job_id: {job_id}, status: {status}, phase: {phase}, progress: {progress}"
            )

            try:
                now = datetime.now(timezone.utc).isoformat()  # ç›´æ¥è½‰ç‚º ISO å­—ä¸²
                # å…ˆæª¢æŸ¥ç¾æœ‰çš„ job ç‹€æ…‹
                existing_job = cache.get(f"job:{job_id}")
                logger.info(f"ğŸ“‹ ç¾æœ‰ä»»å‹™ç‹€æ…‹: {existing_job}")

                job = existing_job or {}
                job.update(
                    {
                        "job_id": job_id,
                        "video_id": video_id,
                        "status": (
                            status.value if hasattr(status, "value") else status
                        ),  # ç¢ºä¿æšèˆ‰è½‰ç‚ºå­—ä¸²
                        "phase": phase,
                        "progress": progress,
                        "cached": False,
                        "created_at": job.get("created_at", now),
                        "updated_at": now,
                    }
                )
                if extra:
                    job.update(extra)

                # åŸ·è¡Œå¿«å–æ›´æ–°
                logger.info(f"ğŸ’¾ æº–å‚™å¯«å…¥å¿«å– - key: job:{job_id}, ttl: {ttl}")
                success = cache.set(f"job:{job_id}", job, ttl=ttl)
                logger.info(f"ğŸ“ å¿«å–å¯«å…¥çµæœ: {success}")

                # çŸ­æš«å»¶é²å¾Œé©—è­‰å¯«å…¥æ˜¯å¦æˆåŠŸ
                import time

                time.sleep(0.1)
                updated_job = cache.get(f"job:{job_id}")
                logger.info(f"âœ… å¿«å–æ›´æ–°å¾Œé©—è­‰: {updated_job}")

                # æª¢æŸ¥ç‹€æ…‹æ˜¯å¦æ­£ç¢ºæ›´æ–°
                if updated_job and updated_job.get("status") == job.get("status"):
                    logger.info(f"ğŸ‰ ç‹€æ…‹æ›´æ–°ç¢ºèªæˆåŠŸ: {updated_job.get('status')}")
                else:
                    logger.error(
                        f"âŒ ç‹€æ…‹æ›´æ–°å¤±æ•— - æœŸæœ›: {job.get('status')}, å¯¦éš›: {updated_job.get('status') if updated_job else 'None'}"
                    )

            except Exception as e:
                logger.error(f"âŒ æ›´æ–°ä»»å‹™ç‹€æ…‹å¤±æ•—: {e}", exc_info=True)

        # 1. æ›´æ–°ä»»å‹™ç‹€æ…‹ç‚º RUNNING
        update_job("metadata", 0.0, status=JobStatus.RUNNING)
        try:
            # æº–å‚™ crewai kickoff è¼¸å…¥ï¼Œè£œå…… job_id, video_id ä»¥åˆ© callback é€²åº¦æ›´æ–°
            inputs = {
                "job_id": job_id,
                "video_id": video_id,
                "search_subject": "æ‰¾å‡ºæ™¯é»ã€é¤å»³ã€äº¤é€šæ–¹å¼èˆ‡ä½å®¿çš„åœ°ç†ä½ç½®",
            }
            # é€²åº¦: metadata éšæ®µ
            update_job("metadata", 25, status=JobStatus.RUNNING)

            # åŸ·è¡Œ crewai ä¸»æµç¨‹ï¼ˆåŒæ­¥å‘¼å«ï¼Œå¯¦éš›å¯ä¾éœ€æ±‚ç´°åˆ†é€²åº¦ï¼‰
            Trailtag = get_trailtag()
            logger.info(
                f"é–‹å§‹åŸ·è¡Œ CrewAI ä»»å‹™ - job_id: {job_id}, video_id: {video_id}"
            )

            # é€²åº¦: é–‹å§‹åŸ·è¡Œ
            update_job("processing", 50, status=JobStatus.RUNNING)
            output = Trailtag().crew().kickoff(inputs=inputs)

            logger.info(
                f"CrewAI ä»»å‹™å®Œæˆ - job_id: {job_id}, output type: {type(output)}"
            )

            # é€²åº¦: geocode å®Œæˆ â€” å°‡å®Œæˆçš„ job TTL è¨­ç‚º 60 ç§’
            update_job("geocode", 100, status=JobStatus.DONE, ttl=60)

            # çµæœå¯«å…¥ analysis å¿«å–ï¼Œä¾›åœ°åœ–æŸ¥è©¢
            # æ ¹æ“š CrewAI æ–‡æª”ï¼Œcrew().kickoff() è¿”å› CrewOutput ç‰©ä»¶
            if output and hasattr(output, "pydantic") and output.pydantic:
                logger.info("ä½¿ç”¨ output.pydantic å„²å­˜çµæœ")
                cache.set(
                    f"analysis:{video_id}",
                    (
                        output.pydantic.model_dump()
                        if hasattr(output.pydantic, "model_dump")
                        else (
                            output.pydantic.dict()
                            if hasattr(output.pydantic, "dict")
                            else output.pydantic
                        )
                    ),
                )
            elif output and hasattr(output, "json_dict") and output.json_dict:
                logger.info("ä½¿ç”¨ output.json_dict å„²å­˜çµæœ")
                cache.set(f"analysis:{video_id}", output.json_dict)
            elif output and hasattr(output, "raw"):
                logger.info("ä½¿ç”¨ output.raw å„²å­˜çµæœ")
                # å˜—è©¦è§£æ raw è¼¸å‡ºç‚º JSON
                try:
                    import json

                    raw_data = (
                        json.loads(output.raw)
                        if isinstance(output.raw, str)
                        else output.raw
                    )
                    cache.set(f"analysis:{video_id}", raw_data)
                except (json.JSONDecodeError, TypeError):
                    logger.warning(f"ç„¡æ³•è§£æ raw è¼¸å‡ºç‚º JSON: {output.raw}")
                    # ä½¿ç”¨åŸå§‹å­—ä¸²ä½œç‚ºå‚™ç”¨
                    cache.set(
                        f"analysis:{video_id}",
                        {"raw_output": str(output.raw), "video_id": video_id},
                    )
            else:
                logger.warning(
                    f"CrewAI è¼¸å‡ºæ ¼å¼ä¸ç¬¦é æœŸ: {type(output)}, å±¬æ€§: {dir(output) if hasattr(output, '__dict__') else 'N/A'}"
                )
                # å˜—è©¦å°‡æ•´å€‹è¼¸å‡ºç‰©ä»¶è½‰æ›ç‚ºå­—å…¸
                try:
                    if hasattr(output, "__dict__"):
                        cache.set(f"analysis:{video_id}", output.__dict__)
                    else:
                        cache.set(
                            f"analysis:{video_id}",
                            {"raw_output": str(output), "video_id": video_id},
                        )
                except Exception as e:
                    logger.error(f"å„²å­˜è¼¸å‡ºå¤±æ•—: {e}")

            # ä»»å‹™å®Œæˆï¼Œç§»é™¤ video->job æ˜ å°„ä»¥é¿å… stale state
            try:
                cache.delete(f"video_job:{video_id}")
            except Exception:
                logger.debug({"event": "video_job_delete_failed", "video_id": video_id})
        except Exception as e:
            # crewai åŸ·è¡Œå¤±æ•—ï¼Œè¨˜éŒ„éŒ¯èª¤ä¸¦æ›´æ–° job ç‹€æ…‹
            logger.error({"event": "job_failed", "job_id": job_id, "error": str(e)})
            update_job(
                "geocode",
                0,
                status=JobStatus.FAILED,
                extra={"error": {"type": "exception", "message": str(e)}},
            )
            # ä»»å‹™å¤±æ•—æ™‚ä¹Ÿæ¸…é™¤ video->job æ˜ å°„
            try:
                cache.delete(f"video_job:{video_id}")
            except Exception:
                logger.debug({"event": "video_job_delete_failed", "video_id": video_id})
    except Exception as e:
        # èƒŒæ™¯ä»»å‹™æœ¬èº«è‡´å‘½éŒ¯èª¤
        logger.error({"event": "job_fatal", "job_id": job_id, "error": str(e)})
        try:
            cache.delete(f"video_job:{video_id}")
        except Exception:
            logger.debug({"event": "video_job_delete_failed", "video_id": video_id})


@router.post(
    "/videos/analyze",
    response_model=JobResponse,
    summary="æäº¤å½±ç‰‡åˆ†æä»»å‹™",
    description="æäº¤æ–°çš„ YouTube å½±ç‰‡åˆ†æè«‹æ±‚ï¼Œæ”¯æ´å¿«å–æŸ¥è©¢èˆ‡éåŒæ­¥ä»»å‹™åˆ†æ´¾ã€‚å›å‚³ job_id ä¾›é€²åº¦æŸ¥è©¢ã€‚",
)
async def analyze_video(
    request: AnalyzeRequest, background_tasks: BackgroundTasks
) -> JobResponse:
    """
    æäº¤æ–°çš„å½±ç‰‡åˆ†æè«‹æ±‚ï¼š
    1. å…ˆæª¢æŸ¥å¿«å–ï¼Œè‹¥å‘½ä¸­å‰‡ç›´æ¥å›å‚³å·²å®Œæˆ jobã€‚
    2. è‹¥æœªå‘½ä¸­ï¼Œå»ºç«‹ job ç‹€æ…‹ä¸¦åˆ†æ´¾ crewai ä»»å‹™åˆ°èƒŒæ™¯åŸ·è¡Œã€‚
    3. å›å‚³ job_id ä¾›å‰ç«¯æŸ¥è©¢é€²åº¦ã€‚
    """
    try:
        video_id = extract_video_id(str(request.url))
    except ValueError as e:
        logger.error({"event": "invalid_url", "url": str(request.url), "error": str(e)})
        raise HTTPException(
            status_code=400,
            detail=f"ç„¡æ•ˆçš„ YouTube URLï¼š{str(e)}ã€‚è«‹ç¢ºèª URL æ ¼å¼æ­£ç¢ºï¼Œæ”¯æ´çš„æ ¼å¼åŒ…æ‹¬ youtube.com/watch?v=ID æˆ– youtu.be/ID",
        )

    # å¿«é€Ÿæª¢æ¸¬å­—å¹•å¯ç”¨æ€§
    subtitle_status = check_subtitle_availability(video_id)
    logger.info(
        f"å½±ç‰‡ {video_id} å­—å¹•æª¢æ¸¬çµæœ: available={subtitle_status.available}, confidence={subtitle_status.confidence_score}"
    )

    # å¦‚æœæ²’æœ‰å­—å¹•å¯ç”¨ï¼Œæä¾›å‹å–„çš„éŒ¯èª¤è¨Šæ¯
    if not subtitle_status.available:
        logger.warning(f"å½±ç‰‡ {video_id} ç„¡å¯ç”¨å­—å¹•")
        raise HTTPException(
            status_code=422,
            detail={
                "message": "æ­¤å½±ç‰‡æ²’æœ‰å¯ç”¨çš„å­—å¹•æˆ–è‡ªå‹•å­—å¹•ï¼Œç„¡æ³•é€²è¡Œåˆ†æ",
                "suggestion": "è«‹é¸æ“‡æœ‰å­—å¹•çš„å½±ç‰‡ï¼Œæˆ–è€…ç­‰å¾… YouTube ç”Ÿæˆè‡ªå‹•å­—å¹•å¾Œå†è©¦",
                "video_id": video_id,
                "subtitle_status": subtitle_status.model_dump(),
            },
        )

    # æª¢æŸ¥æ˜¯å¦å·²æœ‰æ­¤å½±ç‰‡çš„åˆ†æçµæœï¼ˆæŸ¥å¿«å–ï¼‰
    cache = get_cache()
    cache_key = f"analysis:{video_id}"
    cached_result = cache.get(cache_key)
    if cached_result:
        logger.info({"event": "cache_hit", "video_id": video_id})
        job_id = str(uuid.uuid4())
        now = datetime.now(timezone.utc)
        job = {
            "job_id": job_id,
            "video_id": video_id,
            "status": JobStatus.DONE,
            "phase": Phase.GEOCODE,
            "progress": 100.0,
            "cached": True,
            "created_at": now,
            "updated_at": now,
            "subtitle_availability": subtitle_status.model_dump(),
        }
        cache.set(f"job:{job_id}", job, ttl=60)
        # å»ºç«‹ video_id -> job_id æ˜ å°„ï¼Œæ–¹ä¾¿ä»¥ video_id æŸ¥è©¢ç›®å‰å°æ‡‰çš„ job
        try:
            cache.set(f"video_job:{video_id}", job_id, ttl=60)
        except Exception:
            # ä¸æ‡‰è©²é˜»æ–·ä¸»æµç¨‹ï¼Œåƒ…è¨˜éŒ„å³å¯
            logger.debug(
                {
                    "event": "video_job_map_failed",
                    "video_id": video_id,
                    "job_id": job_id,
                }
            )
        return JobResponse(**job)

    # å‰µå»ºæ–°ä»»å‹™
    job_id = str(uuid.uuid4())
    now = datetime.now(timezone.utc)
    job = {
        "job_id": job_id,
        "video_id": video_id,
        "status": JobStatus.QUEUED,
        "phase": None,
        "progress": 0.0,
        "cached": False,
        "created_at": now,
        "updated_at": now,
        "subtitle_availability": subtitle_status.model_dump(),
    }
    cache.set(f"job:{job_id}", job)
    # è¨­å®š video_id -> job_id æ˜ å°„ï¼Œæ–¹ä¾¿ä»¥ video_id æŸ¥è©¢ç›®å‰å°æ‡‰çš„ job
    try:
        cache.set(f"video_job:{video_id}", job_id)
    except Exception:
        logger.debug(
            {"event": "video_job_map_failed", "video_id": video_id, "job_id": job_id}
        )
    logger.info({"event": "job_created", "job_id": job_id, "video_id": video_id})

    # åˆ†æ´¾ crewai ä»»å‹™åˆ°èƒŒæ™¯ï¼ŒåŸ·è¡Œåˆ†æèˆ‡é€²åº¦æ›´æ–°
    background_tasks.add_task(run_trailtag_job, job_id, video_id)
    return JobResponse(**job)


# æŸ¥è©¢ä»»å‹™ç‹€æ…‹ API
@router.get(
    "/jobs/{job_id}",
    response_model=JobResponse,
    summary="æŸ¥è©¢ä»»å‹™ç‹€æ…‹",
    description="æ ¹æ“š job_id æŸ¥è©¢åˆ†æä»»å‹™çš„é€²åº¦ã€éšæ®µèˆ‡éŒ¯èª¤è³‡è¨Šã€‚",
)
async def get_job_status(job_id: str = Path(..., description="ä»»å‹™ ID")) -> JobResponse:
    """
    æ ¹æ“š job_id æŸ¥è©¢ä»»å‹™ç‹€æ…‹ï¼Œå›å‚³é€²åº¦ã€éšæ®µã€éŒ¯èª¤ç­‰è³‡è¨Šã€‚
    è‹¥ job ä¸å­˜åœ¨å‰‡å›å‚³ 404ã€‚
    """
    cache = get_cache()
    job = cache.get(f"job:{job_id}")
    if not job:
        logger.warning({"event": "job_not_found", "job_id": job_id})
        raise HTTPException(status_code=404, detail=f"ä»»å‹™ä¸å­˜åœ¨: {job_id}")
    return JobResponse(**job)


# æŸ¥è©¢å½±ç‰‡åœ°é»è¦–è¦ºåŒ–è³‡æ–™ API
@router.get(
    "/videos/{video_id}/locations",
    response_model=MapVisualization,
    summary="æŸ¥è©¢å½±ç‰‡åœ°é»è¦–è¦ºåŒ–è³‡æ–™",
    description="æ ¹æ“š YouTube video_id æŸ¥è©¢åˆ†æå¾Œçš„åœ°é»è¦–è¦ºåŒ–è³‡æ–™ï¼ˆåœ°åœ–è·¯ç·šç­‰ï¼‰ã€‚",
)
async def get_video_locations(
    video_id: str = Path(..., description="YouTube å½±ç‰‡ ID"),
) -> MapVisualization:
    """
    æ ¹æ“š video_id æŸ¥è©¢åˆ†æå¾Œçš„åœ°é»è¦–è¦ºåŒ–è³‡æ–™ï¼ˆåœ°åœ–è·¯ç·šç­‰ï¼‰ã€‚
    è‹¥æŸ¥ç„¡è³‡æ–™å‰‡å›å‚³ 404ã€‚
    """
    cache = get_cache()
    cache_key = f"analysis:{video_id}"
    result = cache.get(cache_key)
    if not result:
        logger.warning({"event": "locations_not_found", "video_id": video_id})
        raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ°å½±ç‰‡åœ°é»è³‡æ–™: {video_id}")
    return MapVisualization(**result)


@router.get(
    "/videos/{video_id}/subtitles/check",
    response_model=SubtitleStatus,
    summary="æª¢æŸ¥å½±ç‰‡å­—å¹•å¯ç”¨æ€§",
    description="å¿«é€Ÿæª¢æ¸¬ YouTube å½±ç‰‡çš„å­—å¹•å¯ç”¨æ€§ï¼ŒåŒ…æ‹¬æ‰‹å‹•å­—å¹•å’Œè‡ªå‹•å­—å¹•è³‡è¨Šã€‚",
)
async def check_video_subtitles(
    video_id: str = Path(..., description="YouTube å½±ç‰‡ ID"),
) -> SubtitleStatus:
    """
    æª¢æŸ¥æŒ‡å®šå½±ç‰‡çš„å­—å¹•å¯ç”¨æ€§ï¼Œå›å‚³è©³ç´°çš„å­—å¹•ç‹€æ…‹è³‡è¨Šã€‚
    ç”¨æ–¼åœ¨åˆ†æå‰å¿«é€Ÿåˆ¤æ–·å½±ç‰‡æ˜¯å¦é©åˆè™•ç†ã€‚
    """
    try:
        subtitle_status = check_subtitle_availability(video_id)
        logger.info(
            f"å­—å¹•æª¢æŸ¥è«‹æ±‚ - å½±ç‰‡: {video_id}, çµæœ: {subtitle_status.available}"
        )
        return subtitle_status
    except Exception as e:
        logger.error(f"å­—å¹•æª¢æŸ¥å¤±æ•— {video_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç„¡æ³•æª¢æŸ¥å½±ç‰‡å­—å¹•ç‹€æ…‹: {str(e)}")


@router.get(
    "/videos/{video_id}/job",
    response_model=JobStatusResponse,
    summary="ä»¥ video_id æŸ¥è©¢å°æ‡‰çš„ job ç‹€æ…‹",
    description="æ ¹æ“š YouTube video_id æŸ¥è©¢ç›®å‰å°æ‡‰çš„ jobï¼ˆè‹¥æœ‰ï¼‰ã€‚è‹¥æœªæ‰¾åˆ°å‰‡å›å‚³ 404ã€‚",
)
async def get_job_by_video(
    video_id: str = Path(..., description="YouTube å½±ç‰‡ ID"),
) -> JobStatusResponse:
    """
    å…ˆå˜—è©¦ä½¿ç”¨ video_job:{video_id} æ˜ å°„å–å¾—å°æ‡‰ job_idï¼Œè‹¥æœªå‘½ä¸­å‰‡å›å‚³ 404ã€‚
    è‹¥å‘½ä¸­å‰‡å›å‚³è©² job çš„ç°¡è¦ç‹€æ…‹ï¼ˆjob_id, status, phase, progress, stats, errorï¼‰ã€‚
    """
    cache = get_cache()
    # å˜—è©¦ç›´æ¥æŸ¥æ‰¾æ˜ å°„
    try:
        mapped = cache.get(f"video_job:{video_id}")
    except Exception:
        mapped = None

    if not mapped:
        # è‹¥æ˜ å°„ä¸å­˜åœ¨ï¼Œå˜—è©¦å›å‚³ 404ï¼ˆé¿å…éæ­·å…¨éƒ¨å¿«å–ï¼‰
        logger.info({"event": "video_job_not_found", "video_id": video_id})
        raise HTTPException(
            status_code=404, detail=f"æ‰¾ä¸åˆ°é‡å°å½±ç‰‡çš„é€²è¡Œä¸­ä»»å‹™: {video_id}"
        )

    job = cache.get(f"job:{mapped}")
    if not job:
        logger.info(
            {"event": "job_not_found_for_video", "video_id": video_id, "job_id": mapped}
        )
        raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ° job: {mapped}")

    # æ§‹å»ºå›å‚³æ ¼å¼
    resp = {
        "job_id": job.get("job_id"),
        "status": job.get("status"),
        "phase": job.get("phase"),
        "progress": job.get("progress", 0),
        "stats": {},
        "error": (
            job.get("error")
            if job.get("status") in [JobStatus.FAILED, JobStatus.CANCELED]
            else None
        ),
    }
    return JobStatusResponse(**resp)
