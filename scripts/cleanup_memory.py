#!/usr/bin/env python3
"""
æ¸…ç† CrewAI è¨˜æ†¶ç³»çµ±è…³æœ¬

æ­¤è…³æœ¬å¯ä»¥æ¸…ç† TrailTag é …ç›®ä¸­çš„ CrewAI è¨˜æ†¶æ¢ç›®å’ŒåŸ·è¡Œç‹€æ…‹ï¼Œ
è§£æ±ºå¡ä½çš„ä»»å‹™å’Œéå¤šè¨˜æ†¶æ¢ç›®çš„å•é¡Œã€‚
"""

import json
import os
import shutil
import sys
from datetime import datetime, timezone
from typing import Dict, List


def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” TrailTag CrewAI è¨˜æ†¶ç³»çµ±æ¸…ç†å·¥å…·")
    print("=" * 50)

    # ç¢ºèªæˆ‘å€‘åœ¨æ­£ç¢ºçš„å°ˆæ¡ˆç›®éŒ„
    if not os.path.exists("crewai_storage"):
        print("âŒ éŒ¯èª¤: æœªæ‰¾åˆ° crewai_storage ç›®éŒ„")
        print("è«‹ç¢ºèªåœ¨ TrailTag å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹åŸ·è¡Œæ­¤è…³æœ¬")
        sys.exit(1)

    # é¡¯ç¤ºç•¶å‰è¨˜æ†¶ç‹€æ…‹
    show_memory_status()

    # è©¢å•ç”¨æˆ¶è¦åŸ·è¡Œçš„æ“ä½œ
    print("\né¸æ“‡è¦åŸ·è¡Œçš„æ“ä½œ:")
    print("1. æ¸…ç†å¡ä½çš„ä»»å‹™ (æ¨è–¦)")
    print("2. æ¸…ç†èˆŠè¨˜æ†¶æ¢ç›® (7å¤©å‰)")
    print("3. å®Œå…¨é‡ç½®è¨˜æ†¶ç³»çµ± (å±éšª)")
    print("4. åƒ…é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯")
    print("0. é€€å‡º")

    choice = input("\nè«‹é¸æ“‡ (0-4): ").strip()

    if choice == "1":
        cleanup_stuck_jobs()
    elif choice == "2":
        cleanup_old_memories()
    elif choice == "3":
        if confirm_reset():
            full_reset()
    elif choice == "4":
        pass  # å·²ç¶“é¡¯ç¤ºäº†çµ±è¨ˆä¿¡æ¯
    elif choice == "0":
        print("ğŸ‘‹ é€€å‡º")
    else:
        print("âŒ ç„¡æ•ˆé¸æ“‡")


def show_memory_status():
    """é¡¯ç¤ºè¨˜æ†¶ç³»çµ±ç‹€æ…‹"""
    print("\nğŸ“Š ç•¶å‰è¨˜æ†¶ç³»çµ±ç‹€æ…‹:")

    # æª¢æŸ¥å„å€‹è¨˜æ†¶æª”æ¡ˆ
    files_info = {
        "agent_memories.json": "ä»£ç†è¨˜æ†¶",
        "job_memories.json": "ä»»å‹™è¨˜æ†¶",
        "analysis_results.json": "åˆ†æçµæœ",
        "crew_memory/memories.json": "Crewè¨˜æ†¶",
    }

    total_entries = 0

    for file_path, description in files_info.items():
        full_path = f"crewai_storage/{file_path}"
        if os.path.exists(full_path):
            try:
                with open(full_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                if isinstance(data, list):
                    count = len(data)
                elif isinstance(data, dict):
                    count = sum(
                        len(v) if isinstance(v, list) else 1 for v in data.values()
                    )
                else:
                    count = 1

                file_size = os.path.getsize(full_path) / 1024  # KB
                print(f"  â€¢ {description}: {count} æ¢ç›® ({file_size:.1f}KB)")
                total_entries += count

                # æª¢æŸ¥å¡ä½çš„ä»»å‹™
                if file_path == "job_memories.json":
                    check_stuck_jobs(data)

            except Exception as e:
                print(f"  â€¢ {description}: è®€å–éŒ¯èª¤ - {e}")
        else:
            print(f"  â€¢ {description}: æª”æ¡ˆä¸å­˜åœ¨")

    print(f"\nğŸ“ˆ ç¸½è¨˜æ†¶æ¢ç›®: {total_entries}")


def check_stuck_jobs(job_data: List[Dict]):
    """æª¢æŸ¥å¡ä½çš„ä»»å‹™"""
    if not job_data:
        return

    current_time = datetime.now(timezone.utc)
    stuck_jobs = []

    for job in job_data:
        if job.get("status") == "running":
            try:
                updated_at = datetime.fromisoformat(
                    job.get("updated_at", "").replace("Z", "+00:00")
                )
                time_diff = current_time - updated_at
                if time_diff.days > 0:  # è¶…é1å¤©çš„é‹è¡Œä»»å‹™
                    stuck_jobs.append(
                        {
                            "job_id": job.get("job_id"),
                            "video_id": job.get("video_id"),
                            "days_stuck": time_diff.days,
                        }
                    )
            except Exception:
                pass

    if stuck_jobs:
        print(f"  âš ï¸  ç™¼ç¾ {len(stuck_jobs)} å€‹å¡ä½çš„ä»»å‹™:")
        for job in stuck_jobs:
            print(
                f"     - {job['job_id'][:8]}... (å½±ç‰‡: {job['video_id']}, å¡ä½ {job['days_stuck']} å¤©)"
            )


def cleanup_stuck_jobs():
    """æ¸…ç†å¡ä½çš„ä»»å‹™"""
    print("\nğŸ§¹ æ¸…ç†å¡ä½çš„ä»»å‹™...")

    job_file = "crewai_storage/job_memories.json"
    if not os.path.exists(job_file):
        print("âœ… æ²’æœ‰ä»»å‹™è¨˜æ†¶æª”æ¡ˆéœ€è¦æ¸…ç†")
        return

    try:
        with open(job_file, "r", encoding="utf-8") as f:
            jobs = json.load(f)

        original_count = len(jobs)
        current_time = datetime.now(timezone.utc)
        cleaned_jobs = []

        for job in jobs:
            if job.get("status") == "running":
                try:
                    updated_at = datetime.fromisoformat(
                        job.get("updated_at", "").replace("Z", "+00:00")
                    )
                    time_diff = current_time - updated_at
                    if time_diff.days > 0:  # è¶…é1å¤©å°±æ¨™è¨˜ç‚ºå¤±æ•—
                        job["status"] = "failed"
                        job["error_message"] = (
                            f"ä»»å‹™å¡ä½è¶…é {time_diff.days} å¤©ï¼Œè‡ªå‹•æ¸…ç†"
                        )
                        job["updated_at"] = current_time.isoformat()
                except Exception:
                    # ç„¡æ•ˆçš„æ™‚é–“æ ¼å¼ä¹Ÿæ¨™è¨˜ç‚ºå¤±æ•—
                    job["status"] = "failed"
                    job["error_message"] = "ç„¡æ•ˆçš„æ›´æ–°æ™‚é–“ï¼Œè‡ªå‹•æ¸…ç†"
                    job["updated_at"] = current_time.isoformat()

            cleaned_jobs.append(job)

        # å‚™ä»½åŸå§‹æª”æ¡ˆ
        backup_path = f"{job_file}.backup.{int(current_time.timestamp())}"
        shutil.copy2(job_file, backup_path)
        print(f"âœ… åŸå§‹æª”æ¡ˆå·²å‚™ä»½åˆ°: {backup_path}")

        # å¯«å…¥æ¸…ç†å¾Œçš„è³‡æ–™
        with open(job_file, "w", encoding="utf-8") as f:
            json.dump(cleaned_jobs, f, ensure_ascii=False, indent=2)

        cleaned_count = original_count - len(
            [j for j in cleaned_jobs if j.get("status") == "running"]
        )
        print(f"âœ… å·²æ¸…ç† {cleaned_count} å€‹å¡ä½çš„ä»»å‹™")

    except Exception as e:
        print(f"âŒ æ¸…ç†å¤±æ•—: {e}")


def cleanup_old_memories():
    """æ¸…ç†èˆŠè¨˜æ†¶æ¢ç›®"""
    print("\nğŸ§¹ æ¸…ç† 7 å¤©å‰çš„è¨˜æ†¶æ¢ç›®...")

    current_time = datetime.now(timezone.utc)
    cutoff_days = 7

    # æ¸…ç†å„å€‹è¨˜æ†¶æª”æ¡ˆ
    files_to_clean = [
        "crewai_storage/agent_memories.json",
        "crewai_storage/crew_memory/memories.json",
    ]

    for file_path in files_to_clean:
        if not os.path.exists(file_path):
            continue

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            original_count = 0
            cleaned_data = None

            if isinstance(data, list):
                original_count = len(data)
                cleaned_data = [
                    item
                    for item in data
                    if not should_remove_by_age(item, current_time, cutoff_days)
                ]
            elif isinstance(data, dict):
                cleaned_data = {}
                for key, value in data.items():
                    if isinstance(value, list):
                        original_count += len(value)
                        cleaned_value = [
                            item
                            for item in value
                            if not should_remove_by_age(item, current_time, cutoff_days)
                        ]
                        if cleaned_value:  # åªä¿ç•™éç©ºçš„åˆ—è¡¨
                            cleaned_data[key] = cleaned_value
                    else:
                        original_count += 1
                        if not should_remove_by_age(value, current_time, cutoff_days):
                            cleaned_data[key] = value

            # å‚™ä»½ä¸¦å¯«å…¥æ¸…ç†å¾Œçš„è³‡æ–™
            if cleaned_data is not None:
                backup_path = f"{file_path}.backup.{int(current_time.timestamp())}"
                shutil.copy2(file_path, backup_path)

                with open(file_path, "w", encoding="utf-8") as f:
                    json.dump(cleaned_data, f, ensure_ascii=False, indent=2)

                new_count = count_items(cleaned_data)
                removed_count = original_count - new_count
                print(
                    f"âœ… {file_path}: ç§»é™¤ {removed_count} å€‹èˆŠæ¢ç›® (å‰©é¤˜ {new_count} å€‹)"
                )

        except Exception as e:
            print(f"âŒ æ¸…ç† {file_path} å¤±æ•—: {e}")


def should_remove_by_age(item: Dict, current_time: datetime, cutoff_days: int) -> bool:
    """åˆ¤æ–·æ¢ç›®æ˜¯å¦æ‡‰è©²å› ç‚ºå¹´é½¡è€Œè¢«ç§»é™¤"""
    time_fields = ["created_at", "updated_at", "stored_at"]

    for field in time_fields:
        if field in item:
            try:
                if field == "stored_at":
                    # stored_at æ˜¯æ™‚é–“æˆ³æ ¼å¼
                    item_time = datetime.fromtimestamp(
                        float(item[field]), tz=timezone.utc
                    )
                else:
                    # å…¶ä»–æ˜¯ ISO æ ¼å¼
                    time_str = item[field].replace("Z", "+00:00")
                    item_time = datetime.fromisoformat(time_str)

                time_diff = current_time - item_time
                return time_diff.days > cutoff_days
            except Exception:
                continue

    return False  # å¦‚æœç„¡æ³•è§£ææ™‚é–“ï¼Œä¿ç•™æ¢ç›®


def count_items(data) -> int:
    """è¨ˆç®—è³‡æ–™ä¸­çš„æ¢ç›®æ•¸é‡"""
    if isinstance(data, list):
        return len(data)
    elif isinstance(data, dict):
        return sum(len(v) if isinstance(v, list) else 1 for v in data.values())
    else:
        return 1


def confirm_reset() -> bool:
    """ç¢ºèªå®Œå…¨é‡ç½®æ“ä½œ"""
    print("\nâš ï¸  è­¦å‘Š: å®Œå…¨é‡ç½®å°‡åˆªé™¤æ‰€æœ‰è¨˜æ†¶æ¢ç›®!")
    print("é€™å°‡:")
    print("  â€¢ åˆªé™¤æ‰€æœ‰ä»£ç†è¨˜æ†¶")
    print("  â€¢ åˆªé™¤æ‰€æœ‰ä»»å‹™è¨˜æ†¶")
    print("  â€¢ åˆªé™¤æ‰€æœ‰åˆ†æçµæœ")
    print("  â€¢ åˆªé™¤æ‰€æœ‰ Crew è¨˜æ†¶")

    confirmation = input("\nè¼¸å…¥ 'DELETE' ç¢ºèªå®Œå…¨é‡ç½®: ")
    return confirmation == "DELETE"


def full_reset():
    """å®Œå…¨é‡ç½®è¨˜æ†¶ç³»çµ±"""
    print("\nğŸ”¥ åŸ·è¡Œå®Œå…¨é‡ç½®...")

    current_time = datetime.now(timezone.utc)
    backup_dir = f"crewai_storage_backup_{int(current_time.timestamp())}"

    try:
        # å‚™ä»½æ•´å€‹ crewai_storage ç›®éŒ„
        if os.path.exists("crewai_storage"):
            shutil.copytree("crewai_storage", backup_dir)
            print(f"âœ… å®Œæ•´å‚™ä»½å·²ä¿å­˜åˆ°: {backup_dir}")

        # åˆªé™¤ä¸¦é‡å»º crewai_storage
        if os.path.exists("crewai_storage"):
            shutil.rmtree("crewai_storage")

        os.makedirs("crewai_storage", exist_ok=True)
        os.makedirs("crewai_storage/crew_memory", exist_ok=True)

        # å‰µå»ºç©ºçš„è¨˜æ†¶æª”æ¡ˆ
        empty_files = {
            "crewai_storage/agent_memories.json": {},
            "crewai_storage/job_memories.json": [],
            "crewai_storage/analysis_results.json": [],
            "crewai_storage/crew_memory/memories.json": [],
        }

        for file_path, empty_content in empty_files.items():
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(empty_content, f, ensure_ascii=False, indent=2)

        print("âœ… è¨˜æ†¶ç³»çµ±å·²å®Œå…¨é‡ç½®")
        print(f"âœ… åŸå§‹è³‡æ–™å‚™ä»½åœ¨: {backup_dir}")

    except Exception as e:
        print(f"âŒ é‡ç½®å¤±æ•—: {e}")


if __name__ == "__main__":
    main()
